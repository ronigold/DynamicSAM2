{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12115e2c-3140-403c-8101-3a18a3ed0f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "from dynamic_sam2.sam2_video_tracker import Sam2VideoTracker\n",
    "from dynamic_sam2.object_detection import YOLODetectionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e9ab236-1a9e-45b6-8fd8-802ba4f76da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Sam2VideoTracker:Loading SAM2 models...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint path: /home/ubuntu/DynamicSAM2/checkpoints/sam2.1_hiera_large.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Sam2VideoTracker:\n",
      "=== Starting Video Processing ===\n",
      "DEBUG:Sam2VideoTracker:Prepared 5 frames for chunk 0-4\n",
      "INFO:Sam2VideoTracker:Processing chunk: current_frame = 0, chunk_end = 4, frames in chunk = 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ubuntu/DynamicSAM2/examples/temp_frames/chunk_0_4/00000.jpg: 384x640 2 persons, 1 bed, 14.9ms\n",
      "Speed: 1.0ms preprocess, 14.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:Sam2VideoTracker:Creating masks for 3 boxes\n",
      "frame loading (JPEG): 100%|██████████| 5/5 [00:00<00:00, 33.93it/s]\n",
      "propagate in video: 100%|██████████| 5/5 [00:01<00:00,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ubuntu/DynamicSAM2/examples/temp_frames/chunk_0_4/00004.jpg: 384x640 1 person, 1 bed, 14.9ms\n",
      "Speed: 1.1ms preprocess, 14.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:Sam2VideoTracker:\n",
      "=== Starting Detection Merge ===\n",
      "INFO:Sam2VideoTracker:Active SAM2 tracks after filtering: 3\n",
      "INFO:Sam2VideoTracker:Filtered SAM2 tracks remaining: 3\n",
      "INFO:Sam2VideoTracker:Active Track 1: ID 1, Box [228 134 631 610], Confidence: 0.932\n",
      "INFO:Sam2VideoTracker:Active Track 2: ID 2, Box [233 156 392 512], Confidence: 0.912\n",
      "INFO:Sam2VideoTracker:Active Track 3: ID 3, Box [  0 501 934 719], Confidence: 0.863\n",
      "INFO:Sam2VideoTracker:DINO new detections: 2\n",
      "INFO:Sam2VideoTracker:New Detection 1: Label person, Box [     224.62      132.52       633.2      615.95], Confidence: 0.930\n",
      "INFO:Sam2VideoTracker:New Detection 2: Label bed, Box [     1.7064      384.73         946      711.18], Confidence: 0.777\n",
      "INFO:Sam2VideoTracker:Updated confidence for tracked object 1: 0.932 -> 0.930\n",
      "INFO:Sam2VideoTracker:Updated confidence for tracked object 3: 0.863 -> 0.777\n",
      "INFO:Sam2VideoTracker:=== Merge Summary ===\n",
      "INFO:Sam2VideoTracker:Initial active tracked objects: 3\n",
      "INFO:Sam2VideoTracker:New objects added: 0\n",
      "INFO:Sam2VideoTracker:Final object count: 3\n",
      "INFO:Sam2VideoTracker:Final Object 1: ID 1, Box [228 134 631 610], Confidence: 0.930\n",
      "INFO:Sam2VideoTracker:Final Object 2: ID 2, Box [233 156 392 512], Confidence: 0.912\n",
      "INFO:Sam2VideoTracker:Final Object 3: ID 3, Box [  0 501 934 719], Confidence: 0.777\n",
      "DEBUG:Sam2VideoTracker:Cleaned up chunk directory: temp_frames/chunk_0_4\n",
      "DEBUG:Sam2VideoTracker:Prepared 5 frames for chunk 4-8\n",
      "INFO:Sam2VideoTracker:Processing chunk: current_frame = 4, chunk_end = 8, frames in chunk = 5\n",
      "frame loading (JPEG): 100%|██████████| 5/5 [00:00<00:00, 34.53it/s]\n",
      "propagate in video: 100%|██████████| 5/5 [00:01<00:00,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ubuntu/DynamicSAM2/examples/temp_frames/chunk_4_8/00008.jpg: 384x640 1 person, 1 bed, 14.9ms\n",
      "Speed: 1.1ms preprocess, 14.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:Sam2VideoTracker:\n",
      "=== Starting Detection Merge ===\n",
      "INFO:Sam2VideoTracker:Active SAM2 tracks after filtering: 3\n",
      "INFO:Sam2VideoTracker:Filtered SAM2 tracks remaining: 3\n",
      "INFO:Sam2VideoTracker:Active Track 1: ID 1, Box [309  24 606 616], Confidence: 0.930\n",
      "INFO:Sam2VideoTracker:Active Track 2: ID 2, Box [335 369 483 558], Confidence: 0.912\n",
      "INFO:Sam2VideoTracker:Active Track 3: ID 3, Box [  0 505 927 719], Confidence: 0.777\n",
      "INFO:Sam2VideoTracker:DINO new detections: 2\n",
      "INFO:Sam2VideoTracker:New Detection 1: Label person, Box [     302.03      22.252      608.18      619.61], Confidence: 0.934\n",
      "INFO:Sam2VideoTracker:New Detection 2: Label bed, Box [     1.0859      395.45      936.19      711.89], Confidence: 0.719\n",
      "INFO:Sam2VideoTracker:Updated confidence for tracked object 1: 0.930 -> 0.934\n",
      "INFO:Sam2VideoTracker:Updated confidence for tracked object 3: 0.777 -> 0.719\n",
      "INFO:Sam2VideoTracker:=== Merge Summary ===\n",
      "INFO:Sam2VideoTracker:Initial active tracked objects: 3\n",
      "INFO:Sam2VideoTracker:New objects added: 0\n",
      "INFO:Sam2VideoTracker:Final object count: 3\n",
      "INFO:Sam2VideoTracker:Final Object 1: ID 1, Box [309  24 606 616], Confidence: 0.934\n",
      "INFO:Sam2VideoTracker:Final Object 2: ID 2, Box [335 369 483 558], Confidence: 0.912\n",
      "INFO:Sam2VideoTracker:Final Object 3: ID 3, Box [  0 505 927 719], Confidence: 0.719\n",
      "DEBUG:Sam2VideoTracker:Cleaned up chunk directory: temp_frames/chunk_4_8\n",
      "DEBUG:Sam2VideoTracker:Prepared 5 frames for chunk 8-12\n",
      "INFO:Sam2VideoTracker:Processing chunk: current_frame = 8, chunk_end = 12, frames in chunk = 5\n",
      "frame loading (JPEG): 100%|██████████| 5/5 [00:00<00:00, 34.43it/s]\n",
      "propagate in video: 100%|██████████| 5/5 [00:01<00:00,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ubuntu/DynamicSAM2/examples/temp_frames/chunk_8_12/00012.jpg: 384x640 1 person, 1 bed, 14.9ms\n",
      "Speed: 1.1ms preprocess, 14.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:Sam2VideoTracker:\n",
      "=== Starting Detection Merge ===\n",
      "INFO:Sam2VideoTracker:Active SAM2 tracks after filtering: 3\n",
      "INFO:Sam2VideoTracker:Filtered SAM2 tracks remaining: 3\n",
      "INFO:Sam2VideoTracker:Active Track 1: ID 1, Box [291  53 517 622], Confidence: 0.934\n",
      "INFO:Sam2VideoTracker:Active Track 2: ID 2, Box [335 415 493 570], Confidence: 0.912\n",
      "INFO:Sam2VideoTracker:Active Track 3: ID 3, Box [  0 520 932 719], Confidence: 0.719\n",
      "INFO:Sam2VideoTracker:DINO new detections: 2\n",
      "INFO:Sam2VideoTracker:New Detection 1: Label person, Box [     284.42       52.88      519.89      627.94], Confidence: 0.931\n",
      "INFO:Sam2VideoTracker:New Detection 2: Label bed, Box [     1.5168      396.25      941.68      711.88], Confidence: 0.837\n",
      "INFO:Sam2VideoTracker:Updated confidence for tracked object 1: 0.934 -> 0.931\n",
      "INFO:Sam2VideoTracker:Updated confidence for tracked object 3: 0.719 -> 0.837\n",
      "INFO:Sam2VideoTracker:=== Merge Summary ===\n",
      "INFO:Sam2VideoTracker:Initial active tracked objects: 3\n",
      "INFO:Sam2VideoTracker:New objects added: 0\n",
      "INFO:Sam2VideoTracker:Final object count: 3\n",
      "INFO:Sam2VideoTracker:Final Object 1: ID 1, Box [291  53 517 622], Confidence: 0.931\n",
      "INFO:Sam2VideoTracker:Final Object 2: ID 2, Box [335 415 493 570], Confidence: 0.912\n",
      "INFO:Sam2VideoTracker:Final Object 3: ID 3, Box [  0 520 932 719], Confidence: 0.837\n",
      "DEBUG:Sam2VideoTracker:Cleaned up chunk directory: temp_frames/chunk_8_12\n",
      "DEBUG:Sam2VideoTracker:Prepared 5 frames for chunk 12-16\n",
      "INFO:Sam2VideoTracker:Processing chunk: current_frame = 12, chunk_end = 16, frames in chunk = 5\n",
      "frame loading (JPEG): 100%|██████████| 5/5 [00:00<00:00, 34.42it/s]\n",
      "propagate in video: 100%|██████████| 5/5 [00:01<00:00,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ubuntu/DynamicSAM2/examples/temp_frames/chunk_12_16/00016.jpg: 384x640 1 person, 1 bed, 15.0ms\n",
      "Speed: 1.1ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:Sam2VideoTracker:\n",
      "=== Starting Detection Merge ===\n",
      "INFO:Sam2VideoTracker:Active SAM2 tracks after filtering: 3\n",
      "INFO:Sam2VideoTracker:Filtered SAM2 tracks remaining: 3\n",
      "INFO:Sam2VideoTracker:Active Track 1: ID 1, Box [ 53  10 393 568], Confidence: 0.931\n",
      "INFO:Sam2VideoTracker:Active Track 2: ID 2, Box [173 208 429 552], Confidence: 0.912\n",
      "INFO:Sam2VideoTracker:Active Track 3: ID 3, Box [  0 510 916 719], Confidence: 0.837\n",
      "INFO:Sam2VideoTracker:DINO new detections: 2\n",
      "INFO:Sam2VideoTracker:New Detection 1: Label person, Box [     51.353      14.969       393.9       574.5], Confidence: 0.933\n",
      "INFO:Sam2VideoTracker:New Detection 2: Label bed, Box [     1.4018      401.31       921.8      712.07], Confidence: 0.789\n",
      "INFO:Sam2VideoTracker:Updated confidence for tracked object 1: 0.931 -> 0.933\n",
      "INFO:Sam2VideoTracker:Updated confidence for tracked object 3: 0.837 -> 0.789\n",
      "INFO:Sam2VideoTracker:=== Merge Summary ===\n",
      "INFO:Sam2VideoTracker:Initial active tracked objects: 3\n",
      "INFO:Sam2VideoTracker:New objects added: 0\n",
      "INFO:Sam2VideoTracker:Final object count: 3\n",
      "INFO:Sam2VideoTracker:Final Object 1: ID 1, Box [ 53  10 393 568], Confidence: 0.933\n",
      "INFO:Sam2VideoTracker:Final Object 2: ID 2, Box [173 208 429 552], Confidence: 0.912\n",
      "INFO:Sam2VideoTracker:Final Object 3: ID 3, Box [  0 510 916 719], Confidence: 0.789\n",
      "DEBUG:Sam2VideoTracker:Cleaned up chunk directory: temp_frames/chunk_12_16\n",
      "DEBUG:Sam2VideoTracker:Prepared 5 frames for chunk 16-20\n",
      "INFO:Sam2VideoTracker:Processing chunk: current_frame = 16, chunk_end = 20, frames in chunk = 5\n",
      "frame loading (JPEG): 100%|██████████| 5/5 [00:00<00:00, 34.40it/s]\n",
      "propagate in video: 100%|██████████| 5/5 [00:01<00:00,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ubuntu/DynamicSAM2/examples/temp_frames/chunk_16_20/00020.jpg: 384x640 2 persons, 1 bed, 14.9ms\n",
      "Speed: 1.1ms preprocess, 14.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:Sam2VideoTracker:\n",
      "=== Starting Detection Merge ===\n",
      "INFO:Sam2VideoTracker:Active SAM2 tracks after filtering: 3\n",
      "INFO:Sam2VideoTracker:Filtered SAM2 tracks remaining: 3\n",
      "INFO:Sam2VideoTracker:Active Track 1: ID 1, Box [144 168 467 711], Confidence: 0.933\n",
      "INFO:Sam2VideoTracker:Active Track 2: ID 2, Box [  0 219 229 550], Confidence: 0.912\n",
      "INFO:Sam2VideoTracker:Active Track 3: ID 3, Box [  0 550 908 719], Confidence: 0.789\n",
      "INFO:Sam2VideoTracker:DINO new detections: 3\n",
      "INFO:Sam2VideoTracker:New Detection 1: Label person, Box [     142.11      162.71      469.77      712.07], Confidence: 0.934\n",
      "INFO:Sam2VideoTracker:New Detection 2: Label person, Box [    0.78101      217.89      229.71      557.86], Confidence: 0.899\n",
      "INFO:Sam2VideoTracker:New Detection 3: Label bed, Box [    0.48041      425.95       916.3       711.9], Confidence: 0.731\n",
      "INFO:Sam2VideoTracker:Updated confidence for tracked object 1: 0.933 -> 0.934\n",
      "INFO:Sam2VideoTracker:Updated confidence for tracked object 2: 0.912 -> 0.899\n",
      "INFO:Sam2VideoTracker:Updated confidence for tracked object 3: 0.789 -> 0.731\n",
      "INFO:Sam2VideoTracker:=== Merge Summary ===\n",
      "INFO:Sam2VideoTracker:Initial active tracked objects: 3\n",
      "INFO:Sam2VideoTracker:New objects added: 0\n",
      "INFO:Sam2VideoTracker:Final object count: 3\n",
      "INFO:Sam2VideoTracker:Final Object 1: ID 1, Box [144 168 467 711], Confidence: 0.934\n",
      "INFO:Sam2VideoTracker:Final Object 2: ID 2, Box [  0 219 229 550], Confidence: 0.899\n",
      "INFO:Sam2VideoTracker:Final Object 3: ID 3, Box [  0 550 908 719], Confidence: 0.731\n",
      "DEBUG:Sam2VideoTracker:Cleaned up chunk directory: temp_frames/chunk_16_20\n",
      "DEBUG:Sam2VideoTracker:Prepared 5 frames for chunk 20-24\n",
      "INFO:Sam2VideoTracker:Processing chunk: current_frame = 20, chunk_end = 24, frames in chunk = 5\n",
      "frame loading (JPEG): 100%|██████████| 5/5 [00:00<00:00, 34.63it/s]\n",
      "propagate in video: 100%|██████████| 5/5 [00:01<00:00,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ubuntu/DynamicSAM2/examples/temp_frames/chunk_20_24/00024.jpg: 384x640 2 persons, 1 bed, 15.0ms\n",
      "Speed: 1.1ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:Sam2VideoTracker:\n",
      "=== Starting Detection Merge ===\n",
      "INFO:Sam2VideoTracker:Active SAM2 tracks after filtering: 3\n",
      "INFO:Sam2VideoTracker:Filtered SAM2 tracks remaining: 3\n",
      "INFO:Sam2VideoTracker:Active Track 1: ID 1, Box [269  24 576 659], Confidence: 0.934\n",
      "INFO:Sam2VideoTracker:Active Track 2: ID 2, Box [  0 392 156 711], Confidence: 0.899\n",
      "INFO:Sam2VideoTracker:Active Track 3: ID 3, Box [  0 542 960 719], Confidence: 0.731\n",
      "INFO:Sam2VideoTracker:DINO new detections: 3\n",
      "INFO:Sam2VideoTracker:New Detection 1: Label person, Box [     266.14      25.259      577.34      669.05], Confidence: 0.938\n",
      "INFO:Sam2VideoTracker:New Detection 2: Label person, Box [    0.26927      391.66      134.06      710.62], Confidence: 0.933\n",
      "INFO:Sam2VideoTracker:New Detection 3: Label bed, Box [   0.042236      437.03      974.18      710.98], Confidence: 0.809\n",
      "INFO:Sam2VideoTracker:Updated confidence for tracked object 1: 0.934 -> 0.938\n",
      "INFO:Sam2VideoTracker:Updated confidence for tracked object 2: 0.899 -> 0.933\n",
      "INFO:Sam2VideoTracker:Updated confidence for tracked object 3: 0.731 -> 0.809\n",
      "INFO:Sam2VideoTracker:=== Merge Summary ===\n",
      "INFO:Sam2VideoTracker:Initial active tracked objects: 3\n",
      "INFO:Sam2VideoTracker:New objects added: 0\n",
      "INFO:Sam2VideoTracker:Final object count: 3\n",
      "INFO:Sam2VideoTracker:Final Object 1: ID 1, Box [269  24 576 659], Confidence: 0.938\n",
      "INFO:Sam2VideoTracker:Final Object 2: ID 2, Box [  0 392 156 711], Confidence: 0.933\n",
      "INFO:Sam2VideoTracker:Final Object 3: ID 3, Box [  0 542 960 719], Confidence: 0.809\n",
      "DEBUG:Sam2VideoTracker:Cleaned up chunk directory: temp_frames/chunk_20_24\n",
      "DEBUG:Sam2VideoTracker:Prepared 5 frames for chunk 24-28\n",
      "INFO:Sam2VideoTracker:Processing chunk: current_frame = 24, chunk_end = 28, frames in chunk = 5\n",
      "frame loading (JPEG): 100%|██████████| 5/5 [00:00<00:00, 34.30it/s]\n",
      "propagate in video: 100%|██████████| 5/5 [00:01<00:00,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ubuntu/DynamicSAM2/examples/temp_frames/chunk_24_28/00028.jpg: 384x640 2 persons, 1 bed, 14.9ms\n",
      "Speed: 1.1ms preprocess, 14.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:Sam2VideoTracker:\n",
      "=== Starting Detection Merge ===\n",
      "INFO:Sam2VideoTracker:Active SAM2 tracks after filtering: 3\n",
      "INFO:Sam2VideoTracker:Filtered SAM2 tracks remaining: 3\n",
      "INFO:Sam2VideoTracker:Active Track 1: ID 1, Box [456 102 662 648], Confidence: 0.938\n",
      "INFO:Sam2VideoTracker:Active Track 2: ID 2, Box [  0 113 234 705], Confidence: 0.933\n",
      "INFO:Sam2VideoTracker:Active Track 3: ID 3, Box [   0  537 1018  719], Confidence: 0.809\n",
      "INFO:Sam2VideoTracker:DINO new detections: 3\n",
      "INFO:Sam2VideoTracker:New Detection 1: Label person, Box [    0.25798      113.25      236.32      707.85], Confidence: 0.940\n",
      "INFO:Sam2VideoTracker:New Detection 2: Label person, Box [     451.45       99.11      666.29      655.89], Confidence: 0.921\n",
      "INFO:Sam2VideoTracker:New Detection 3: Label bed, Box [     1.6567      432.35      1024.2      711.79], Confidence: 0.909\n",
      "INFO:Sam2VideoTracker:Updated confidence for tracked object 2: 0.933 -> 0.940\n",
      "INFO:Sam2VideoTracker:Updated confidence for tracked object 1: 0.938 -> 0.921\n",
      "INFO:Sam2VideoTracker:Updated confidence for tracked object 3: 0.809 -> 0.909\n",
      "INFO:Sam2VideoTracker:=== Merge Summary ===\n",
      "INFO:Sam2VideoTracker:Initial active tracked objects: 3\n",
      "INFO:Sam2VideoTracker:New objects added: 0\n",
      "INFO:Sam2VideoTracker:Final object count: 3\n",
      "INFO:Sam2VideoTracker:Final Object 1: ID 1, Box [456 102 662 648], Confidence: 0.921\n",
      "INFO:Sam2VideoTracker:Final Object 2: ID 2, Box [  0 113 234 705], Confidence: 0.940\n",
      "INFO:Sam2VideoTracker:Final Object 3: ID 3, Box [   0  537 1018  719], Confidence: 0.909\n",
      "DEBUG:Sam2VideoTracker:Cleaned up chunk directory: temp_frames/chunk_24_28\n",
      "DEBUG:Sam2VideoTracker:Prepared 5 frames for chunk 28-32\n",
      "INFO:Sam2VideoTracker:Processing chunk: current_frame = 28, chunk_end = 32, frames in chunk = 5\n",
      "frame loading (JPEG): 100%|██████████| 5/5 [00:00<00:00, 33.82it/s]\n",
      "propagate in video: 100%|██████████| 5/5 [00:01<00:00,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ubuntu/DynamicSAM2/examples/temp_frames/chunk_28_32/00032.jpg: 384x640 2 persons, 1 bed, 14.9ms\n",
      "Speed: 1.1ms preprocess, 14.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:Sam2VideoTracker:\n",
      "=== Starting Detection Merge ===\n",
      "INFO:Sam2VideoTracker:Active SAM2 tracks after filtering: 3\n",
      "INFO:Sam2VideoTracker:Filtered SAM2 tracks remaining: 3\n",
      "INFO:Sam2VideoTracker:Active Track 1: ID 1, Box [371  93 627 642], Confidence: 0.921\n",
      "INFO:Sam2VideoTracker:Active Track 2: ID 2, Box [ 76  74 272 697], Confidence: 0.940\n",
      "INFO:Sam2VideoTracker:Active Track 3: ID 3, Box [   0  550 1005  719], Confidence: 0.909\n",
      "INFO:Sam2VideoTracker:DINO new detections: 3\n",
      "INFO:Sam2VideoTracker:New Detection 1: Label person, Box [     365.91      94.164      632.93      651.15], Confidence: 0.931\n",
      "INFO:Sam2VideoTracker:New Detection 2: Label bed, Box [     1.7675      444.53      1010.8      712.82], Confidence: 0.912\n",
      "INFO:Sam2VideoTracker:New Detection 3: Label person, Box [     73.732      73.103      277.13      700.29], Confidence: 0.903\n",
      "INFO:Sam2VideoTracker:Updated confidence for tracked object 1: 0.921 -> 0.931\n",
      "INFO:Sam2VideoTracker:Updated confidence for tracked object 3: 0.909 -> 0.912\n",
      "INFO:Sam2VideoTracker:Updated confidence for tracked object 2: 0.940 -> 0.903\n",
      "INFO:Sam2VideoTracker:=== Merge Summary ===\n",
      "INFO:Sam2VideoTracker:Initial active tracked objects: 3\n",
      "INFO:Sam2VideoTracker:New objects added: 0\n",
      "INFO:Sam2VideoTracker:Final object count: 3\n",
      "INFO:Sam2VideoTracker:Final Object 1: ID 1, Box [371  93 627 642], Confidence: 0.931\n",
      "INFO:Sam2VideoTracker:Final Object 2: ID 2, Box [ 76  74 272 697], Confidence: 0.903\n",
      "INFO:Sam2VideoTracker:Final Object 3: ID 3, Box [   0  550 1005  719], Confidence: 0.912\n",
      "DEBUG:Sam2VideoTracker:Cleaned up chunk directory: temp_frames/chunk_28_32\n",
      "DEBUG:Sam2VideoTracker:Prepared 2 frames for chunk 32-33\n",
      "INFO:Sam2VideoTracker:Processing chunk: current_frame = 32, chunk_end = 33, frames in chunk = 2\n",
      "frame loading (JPEG): 100%|██████████| 2/2 [00:00<00:00, 34.95it/s]\n",
      "propagate in video: 100%|██████████| 2/2 [00:00<00:00,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ubuntu/DynamicSAM2/examples/temp_frames/chunk_32_33/00033.jpg: 384x640 2 persons, 1 bed, 14.8ms\n",
      "Speed: 1.1ms preprocess, 14.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:Sam2VideoTracker:\n",
      "=== Starting Detection Merge ===\n",
      "INFO:Sam2VideoTracker:Active SAM2 tracks after filtering: 3\n",
      "INFO:Sam2VideoTracker:Filtered SAM2 tracks remaining: 3\n",
      "INFO:Sam2VideoTracker:Active Track 1: ID 1, Box [391  62 632 480], Confidence: 0.931\n",
      "INFO:Sam2VideoTracker:Active Track 2: ID 2, Box [132   0 349 566], Confidence: 0.903\n",
      "INFO:Sam2VideoTracker:Active Track 3: ID 3, Box [  0 559 999 719], Confidence: 0.912\n",
      "INFO:Sam2VideoTracker:DINO new detections: 3\n",
      "INFO:Sam2VideoTracker:New Detection 1: Label person, Box [     129.93           0      351.88      570.17], Confidence: 0.931\n",
      "INFO:Sam2VideoTracker:New Detection 2: Label bed, Box [     1.7151       453.3      1004.5      712.64], Confidence: 0.911\n",
      "INFO:Sam2VideoTracker:New Detection 3: Label person, Box [     389.05      63.989      636.86      485.42], Confidence: 0.860\n",
      "INFO:Sam2VideoTracker:Updated confidence for tracked object 2: 0.903 -> 0.931\n",
      "INFO:Sam2VideoTracker:Updated confidence for tracked object 3: 0.912 -> 0.911\n",
      "INFO:Sam2VideoTracker:Updated confidence for tracked object 1: 0.931 -> 0.860\n",
      "INFO:Sam2VideoTracker:=== Merge Summary ===\n",
      "INFO:Sam2VideoTracker:Initial active tracked objects: 3\n",
      "INFO:Sam2VideoTracker:New objects added: 0\n",
      "INFO:Sam2VideoTracker:Final object count: 3\n",
      "INFO:Sam2VideoTracker:Final Object 1: ID 1, Box [391  62 632 480], Confidence: 0.860\n",
      "INFO:Sam2VideoTracker:Final Object 2: ID 2, Box [132   0 349 566], Confidence: 0.931\n",
      "INFO:Sam2VideoTracker:Final Object 3: ID 3, Box [  0 559 999 719], Confidence: 0.911\n",
      "DEBUG:Sam2VideoTracker:Cleaned up chunk directory: temp_frames/chunk_32_33\n",
      "INFO:Sam2VideoTracker:Filtered out 0 objects with fewer than 5 valid frames\n",
      "INFO:Sam2VideoTracker:Creating final video with only valid objects...\n",
      "DEBUG:Sam2VideoTracker:First frame path: tracking_results/00000_tracked.jpg\n",
      "DEBUG:Sam2VideoTracker:First frame exists: True\n",
      "INFO:Sam2VideoTracker:Creating video from 34 frames\n",
      "INFO:Sam2VideoTracker:Target FPS: 5\n",
      "INFO:Sam2VideoTracker:Output path: tracking_results/tracked.mp4\n",
      "INFO:Sam2VideoTracker:Creating video with OpenCV\n",
      "INFO:Sam2VideoTracker:Creating video at 5 fps, resolution: 1280x720\n",
      "INFO:Sam2VideoTracker:Successfully opened writer with codec mp4v\n",
      "Writing frames: 100%|██████████| 34/34 [00:00<00:00, 97.29it/s]\n",
      "INFO:Sam2VideoTracker:Successfully wrote 34/34 frames\n",
      "INFO:Sam2VideoTracker:OpenCV video saved at: tracking_results/tracked.mp4\n",
      "INFO:Sam2VideoTracker:Renamed output video to: tracking_results/bedroom_tracked.mp4\n",
      "INFO:Sam2VideoTracker:Tracking complete. Found 3 unique objects after filtering.\n",
      "DEBUG:Sam2VideoTracker:Cleaned up temporary frames directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.1 s, sys: 1.5 s, total: 30.6 s\n",
      "Wall time: 22.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "yolo_detector = YOLODetectionModel(\n",
    "    model_path=\"yolo11x.pt\",\n",
    "    device=\"cuda\",\n",
    "    conf_threshold=0.3,\n",
    "    iou_threshold=0.45\n",
    ")\n",
    "\n",
    "tracker = Sam2VideoTracker(\n",
    "    video_path=\"../assets/bedroom.mp4\",\n",
    "    detection_model=yolo_detector,\n",
    "    output_dir=\"tracking_results\",\n",
    "    frames_dir=\"temp_frames\",\n",
    "    check_interval=5,\n",
    "    device=\"cuda\",\n",
    "    target_fps=5,\n",
    "    target_resolution=(1280, 720),\n",
    "    save_masks=False\n",
    ")\n",
    "\n",
    "obj = tracker.process_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee1ca638-5f30-49c2-b6ef-27f535988e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'frames': {0: [415, 0, 686, 528],\n",
       "   1: [389, 119, 649, 635],\n",
       "   2: [304, 0, 604, 538],\n",
       "   3: [221, 58, 637, 602],\n",
       "   4: [229, 135, 631, 610],\n",
       "   5: [244, 71, 649, 591],\n",
       "   6: [255, 123, 643, 635],\n",
       "   7: [269, 19, 664, 581],\n",
       "   8: [309, 24, 606, 615],\n",
       "   9: [318, 123, 619, 640],\n",
       "   10: [237, 5, 603, 578],\n",
       "   11: [277, 91, 544, 637],\n",
       "   12: [291, 53, 516, 621],\n",
       "   13: [244, 0, 500, 595],\n",
       "   14: [189, 120, 428, 698],\n",
       "   15: [79, 10, 441, 617],\n",
       "   16: [54, 11, 393, 568],\n",
       "   17: [73, 157, 404, 670],\n",
       "   18: [53, 0, 389, 589],\n",
       "   19: [62, 0, 409, 592],\n",
       "   20: [144, 168, 466, 710],\n",
       "   21: [196, 0, 525, 642],\n",
       "   22: [250, 12, 508, 687],\n",
       "   23: [280, 169, 495, 719],\n",
       "   24: [269, 24, 575, 659],\n",
       "   25: [339, 65, 677, 660],\n",
       "   26: [347, 142, 686, 691],\n",
       "   27: [375, 10, 692, 594],\n",
       "   28: [456, 102, 661, 648],\n",
       "   29: [457, 109, 649, 642],\n",
       "   30: [418, 22, 678, 490],\n",
       "   31: [446, 127, 735, 643],\n",
       "   32: [371, 93, 626, 642],\n",
       "   33: [391, 62, 632, 480]},\n",
       "  'class': 'person',\n",
       "  'confidence': {0: 0.9320861101150513,\n",
       "   1: 0.9320861101150513,\n",
       "   2: 0.9320861101150513,\n",
       "   3: 0.9320861101150513,\n",
       "   4: 0.9297216534614563,\n",
       "   5: 0.9297216534614563,\n",
       "   6: 0.9297216534614563,\n",
       "   7: 0.9297216534614563,\n",
       "   8: 0.9337966442108154,\n",
       "   9: 0.9337966442108154,\n",
       "   10: 0.9337966442108154,\n",
       "   11: 0.9337966442108154,\n",
       "   12: 0.9310394525527954,\n",
       "   13: 0.9310394525527954,\n",
       "   14: 0.9310394525527954,\n",
       "   15: 0.9310394525527954,\n",
       "   16: 0.9332965016365051,\n",
       "   17: 0.9332965016365051,\n",
       "   18: 0.9332965016365051,\n",
       "   19: 0.9332965016365051,\n",
       "   20: 0.9342185258865356,\n",
       "   21: 0.9342185258865356,\n",
       "   22: 0.9342185258865356,\n",
       "   23: 0.9342185258865356,\n",
       "   24: 0.9375742673873901,\n",
       "   25: 0.9375742673873901,\n",
       "   26: 0.9375742673873901,\n",
       "   27: 0.9375742673873901,\n",
       "   28: 0.9211245775222778,\n",
       "   29: 0.9211245775222778,\n",
       "   30: 0.9211245775222778,\n",
       "   31: 0.9211245775222778,\n",
       "   32: 0.9308013319969177,\n",
       "   33: 0.8597604632377625}},\n",
       " 2: {'frames': {0: [195, 180, 389, 539],\n",
       "   1: [231, 179, 402, 504],\n",
       "   2: [251, 325, 414, 589],\n",
       "   3: [237, 224, 392, 560],\n",
       "   4: [234, 157, 391, 512],\n",
       "   5: [260, 295, 437, 583],\n",
       "   6: [252, 256, 417, 579],\n",
       "   7: [286, 190, 424, 507],\n",
       "   8: [335, 370, 456, 558],\n",
       "   9: [353, 326, 448, 559],\n",
       "   10: [338, 235, 507, 497],\n",
       "   11: [297, 365, 522, 548],\n",
       "   12: [335, 416, 493, 570],\n",
       "   13: [343, 292, 459, 510],\n",
       "   14: [227, 311, 435, 499],\n",
       "   15: [252, 432, 418, 572],\n",
       "   16: [173, 209, 429, 551],\n",
       "   17: [120, 212, 402, 502],\n",
       "   18: [136, 367, 340, 632],\n",
       "   19: [91, 254, 318, 589],\n",
       "   20: [0, 219, 229, 550],\n",
       "   21: [0, 358, 221, 667],\n",
       "   22: [0, 237, 262, 608],\n",
       "   23: [0, 219, 173, 609],\n",
       "   24: [0, 392, 156, 711],\n",
       "   25: [0, 314, 164, 690],\n",
       "   26: [0, 67, 216, 656],\n",
       "   27: [22, 0, 217, 600],\n",
       "   28: [0, 114, 234, 705],\n",
       "   29: [55, 0, 255, 649],\n",
       "   30: [66, 0, 282, 564],\n",
       "   31: [0, 62, 304, 682],\n",
       "   32: [76, 74, 271, 697],\n",
       "   33: [132, 0, 349, 566]},\n",
       "  'class': 'person',\n",
       "  'confidence': {0: 0.9117856025695801,\n",
       "   1: 0.9117856025695801,\n",
       "   2: 0.9117856025695801,\n",
       "   3: 0.9117856025695801,\n",
       "   4: 0.9117856025695801,\n",
       "   5: 0.9117856025695801,\n",
       "   6: 0.9117856025695801,\n",
       "   7: 0.9117856025695801,\n",
       "   8: 0.9117856025695801,\n",
       "   9: 0.9117856025695801,\n",
       "   10: 0.9117856025695801,\n",
       "   11: 0.9117856025695801,\n",
       "   12: 0.9117856025695801,\n",
       "   13: 0.9117856025695801,\n",
       "   14: 0.9117856025695801,\n",
       "   15: 0.9117856025695801,\n",
       "   16: 0.9117856025695801,\n",
       "   17: 0.9117856025695801,\n",
       "   18: 0.9117856025695801,\n",
       "   19: 0.9117856025695801,\n",
       "   20: 0.8993501663208008,\n",
       "   21: 0.8993501663208008,\n",
       "   22: 0.8993501663208008,\n",
       "   23: 0.8993501663208008,\n",
       "   24: 0.9327272772789001,\n",
       "   25: 0.9327272772789001,\n",
       "   26: 0.9327272772789001,\n",
       "   27: 0.9327272772789001,\n",
       "   28: 0.9400278329849243,\n",
       "   29: 0.9400278329849243,\n",
       "   30: 0.9400278329849243,\n",
       "   31: 0.9400278329849243,\n",
       "   32: 0.9027236104011536,\n",
       "   33: 0.9309061765670776}},\n",
       " 3: {'frames': {0: [0, 478, 956, 719],\n",
       "   1: [0, 482, 951, 719],\n",
       "   2: [0, 496, 945, 719],\n",
       "   3: [0, 495, 939, 719],\n",
       "   4: [0, 503, 934, 719],\n",
       "   5: [0, 502, 932, 719],\n",
       "   6: [0, 514, 930, 719],\n",
       "   7: [0, 498, 928, 719],\n",
       "   8: [0, 505, 926, 719],\n",
       "   9: [0, 509, 930, 719],\n",
       "   10: [0, 501, 932, 719],\n",
       "   11: [0, 505, 933, 719],\n",
       "   12: [0, 521, 931, 719],\n",
       "   13: [0, 506, 929, 719],\n",
       "   14: [0, 505, 924, 719],\n",
       "   15: [0, 526, 918, 719],\n",
       "   16: [0, 510, 916, 719],\n",
       "   17: [0, 504, 912, 719],\n",
       "   18: [0, 510, 907, 719],\n",
       "   19: [0, 518, 906, 719],\n",
       "   20: [0, 550, 908, 719],\n",
       "   21: [0, 537, 915, 719],\n",
       "   22: [0, 542, 927, 719],\n",
       "   23: [0, 548, 944, 719],\n",
       "   24: [0, 542, 960, 719],\n",
       "   25: [0, 543, 979, 719],\n",
       "   26: [0, 542, 996, 719],\n",
       "   27: [0, 539, 1009, 719],\n",
       "   28: [0, 537, 1018, 719],\n",
       "   29: [0, 459, 1024, 719],\n",
       "   30: [0, 538, 1021, 719],\n",
       "   31: [0, 541, 1014, 719],\n",
       "   32: [0, 550, 1005, 719],\n",
       "   33: [0, 559, 999, 719]},\n",
       "  'class': 'bed',\n",
       "  'confidence': {0: 0.863264799118042,\n",
       "   1: 0.863264799118042,\n",
       "   2: 0.863264799118042,\n",
       "   3: 0.863264799118042,\n",
       "   4: 0.7771748900413513,\n",
       "   5: 0.7771748900413513,\n",
       "   6: 0.7771748900413513,\n",
       "   7: 0.7771748900413513,\n",
       "   8: 0.7185280323028564,\n",
       "   9: 0.7185280323028564,\n",
       "   10: 0.7185280323028564,\n",
       "   11: 0.7185280323028564,\n",
       "   12: 0.8365696668624878,\n",
       "   13: 0.8365696668624878,\n",
       "   14: 0.8365696668624878,\n",
       "   15: 0.8365696668624878,\n",
       "   16: 0.7890576720237732,\n",
       "   17: 0.7890576720237732,\n",
       "   18: 0.7890576720237732,\n",
       "   19: 0.7890576720237732,\n",
       "   20: 0.730875551700592,\n",
       "   21: 0.730875551700592,\n",
       "   22: 0.730875551700592,\n",
       "   23: 0.730875551700592,\n",
       "   24: 0.8089029788970947,\n",
       "   25: 0.8089029788970947,\n",
       "   26: 0.8089029788970947,\n",
       "   27: 0.8089029788970947,\n",
       "   28: 0.9092735052108765,\n",
       "   29: 0.9092735052108765,\n",
       "   30: 0.9092735052108765,\n",
       "   31: 0.9092735052108765,\n",
       "   32: 0.9118576645851135,\n",
       "   33: 0.9108938574790955}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ffaaf2-6cd0-4b86-b68c-caa987d0c37a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Grounded-Sam2",
   "language": "python",
   "name": "grounded_sam2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
